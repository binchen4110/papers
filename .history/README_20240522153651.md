# About

## Stay active in learning, one paper a day! 

Motivated by [Fredrik](https://www.fregu856.com/), I categorize, annotate and write comments for all research papers I read (10 papers since 2024). 


#### Categories:

[Uncertainty], [MultiModal], [MultiModal KGC], [TKG], [Multimodal Retrieval], [Contrastive Learning], [CV], [Image Edit], [Diffusion model], [LLM], [RAG], [Graph], [Query-Focused Summarization], [KG], [QA System], [continual Learning], [Anti-forgetting learning], [Image Retrieval], [Knowledge Edit]


### Papers:

- [Papers Read in 2024](#papers-read-in-2024)



#### Papers Read in 2024:


##### [2024-05-22] [paper10]
- Epistemic Neural Networks [[pdf]](https://arxiv.org/pdf/2402.16123) [[annotated pdf]](https://github.com/binchen4110/reading_papers/blob/main/commented_pdfs/InstructEdit%20Instruction-Based%20Knowledge%20Editing%20for%20Large%20Language%20Models.pdf)
- *Ningyu Zhang, Bozhong Tian, Siyuan Cheng, Xiaozhuan Liang, Yi Hu, Kouying Xue, Yanjie Gou, Xi Chen, Huajun Chen*
- `IJCAI 2024`
- [Knowledge Edit]
```
General comments on paper quality:
practical; hard to read;
```

```
Personal comment (in detail):
LLM knowledge edit; 实现Knowledge Editing的手段有两个：(1) 更新参数；（2）增加一部分参数并训练它。本文旨在解决针对multi-task的Knowledge Editing，使得任务之间不会有相互影响，感觉就简单的使用的拼接操作；

讲真，看不太明白。
```

##### [2024-05-20] [paper10]
- InstructEdit: Instruction-Based Knowledge Editing for Large Language Models [[pdf]](https://arxiv.org/pdf/2402.16123) [[annotated pdf]](https://github.com/binchen4110/reading_papers/blob/main/commented_pdfs/InstructEdit%20Instruction-Based%20Knowledge%20Editing%20for%20Large%20Language%20Models.pdf)
- *Ningyu Zhang, Bozhong Tian, Siyuan Cheng, Xiaozhuan Liang, Yi Hu, Kouying Xue, Yanjie Gou, Xi Chen, Huajun Chen*
- `IJCAI 2024`
- [Knowledge Edit]
```
General comments on paper quality:
practical; hard to read;
```

```
Personal comment (in detail):
LLM knowledge edit; 实现Knowledge Editing的手段有两个：(1) 更新参数；（2）增加一部分参数并训练它。本文旨在解决针对multi-task的Knowledge Editing，使得任务之间不会有相互影响，感觉就简单的使用的拼接操作；

讲真，看不太明白。
```

##### [2024-05-18] [paper9]
- AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities [[pdf]](https://arxiv.org/pdf/2308.04992) [[annotated pdf]](https://github.com/binchen4110/reading_papers/blob/main/commented_pdfs/AspectMMKG%20A%20Multi-modal%20Knowledge%20Graph%20with.pdf)
- *Jingdan Zhang, Jiaan Wang, Xiaodan Wang, Zhixu Li, Yanghua Xiao*
- `CIKM 2023`
- [MultiModal] [KG] [Image Retrieval] [Multimodal Retrieval]
```
General comments on paper quality:
dataset resource paper; entity aspect linking task(小众任务); huge workload; easy to read;
```

```
Personal comment (in detail):
一个数据集paper; 提出了新的MMKG, 提供了aspect相关的image,；其有别于传统的MMKG，它里面的三元组长这样（entity, aspect, related image）; 其所对应的下游任务为entity aspect linking(很小众)；即根据实体相关的一段文字，预测其在描述对应实体的那一方面；进一步地，还提出了一个aspect-related image retrieval模型；

任务很小众；technique不是很novel;
```

##### [2024-05-17] [paper8]
- Tackling Long-Tail Entities for Temporal Knowledge Graph Completion [[pdf]](https://dl.acm.org/doi/pdf/10.1145/3589335.3651565) [[annotated pdf]](https://github.com/binchen4110/reading_papers/blob/main/commented_pdfs/Tackling%20Long-Tail%20Entities%20for%20Temporal%20Knowledge%20Graph.pdf)
- *Mehrnoosh Mirtaheri, Ryan A. Rossi, Sungchul Kim, Kanak Mahadik, Tong Yu, Xiang Chen, Mohammad Rostami*
- `WWW 2024`
- [TKG] [continual Learning] [Anti-forgetting learning]
```
General comments on paper quality:
short paper; fairly novel; very practical and interesting; easy to read;
```

```
Personal comment (in detail):
Long-tail TKG; 利用全局相似度增强long-tail实体的表示学习；核心是公式（1）；文中采用了多任务划分的持续学习设置，同时由做了抗遗忘性的实验（抗遗忘学习），在TITer上的效果看起来还不错，但是Figure3完全不能体现其所声明的解决了尾部实体学习的问题。

此外，简单说下抗遗忘学习和持续学习（增量学习）的区别：
增量学习：重点在于逐步更新模型以适应新数据。
抗遗忘学习：重点在于在学习新任务时，保持对先前任务的知识。
```

##### [2024-05-16] [paper7]
- Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering [[pdf]](https://arxiv.org/pdf/2404.17723) [[annotated pdf]](https://github.com/binchen4110/reading_papers/blob/main/commented_pdfs/Retrieval-Augmented%20Generation%20with%20Knowledge%20Graphs%20for.pdf)
- *Zhentao Xu, Mark Jerome Cruz, Matthew Guevara, Tie Wang, Manasi Deshpande, Xiaofeng Wang, Zheng Li*
- `SIGIR 2024`
- [LLM] [RAG] [KG] [QA System]
```
General comments on paper quality:
short paper; a little novel; very practical and interesting; easy to read;
```

```
Personal comment (in detail):
RAG vs. KG; 任务为基于LLM, RAG自动问答系统；不同于传统的text-based RAG, 本文使用基于KG的RAG技术；如何把过去的问答案例构造为KG是一个关键（问答内部按规则解析为树的结果，相关问答之间添加联系遍），同时也解析query，并将其用于在KG里检索，检索完成后即利用LLM生成答案。

dataset虽然只有一个，但是LinkIN出品的，来源于工业界，且效果极好，响应时间短。也许这就是工业界的优势：有各种业务上的问题，自然就有不断的新坑产生，idea产生，论产学研结合对经济发展的重要性。。。

感悟：RAG与其说是一种特定的技术，不如说是一种概念，其可以用各种各样的技术实现。
```


##### [2024-05-15] [paper6]
- From Local to Global: A Graph RAG Approach to Query-Focused Summarization [[pdf]](https://arxiv.org/pdf/2404.16130) [[annotated pdf]](https://github.com/binchen4110/reading_papers/blob/main/commented_pdfs/From%20Local%20to%20Global%20A%20Graph%20RAG%20Approach%20to.pdf)
- *Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, Jonathan Larson*
- `Arxiv 2024`
- [LLM] [RAG] [Graph] [Query-Focused Summarization]
```
General comments on paper quality:
a little novel; very industrial and interesting; easy to read;
```

```
Personal comment (in detail):
利用RAG和graph_index技术去解决Query-focused summarization任务，主要创新点，个人任务来源于整个pipline的制定，引入了graph分区，及各个graph分区上的总结抽取技术。有点分布式提取相关总结，再合并的味道；全流程包括KG的生成，相应元素及各分区的总结都由LLM生成; Figure4看不明白；

该技术算是对主流embedding-based RAG技术的一种补充。技术味道浓厚。
微软出品，挺有意思的。
```

##### [2024-05-14] [paper5]
- InstantID: Zero-shot Identity-Preserving Generation in Seconds [[pdf]](https://arxiv.org/pdf/2401.07519) [[annotated pdf]](https://github.com/binchen4110/reading_papers/blob/main/commented_pdfs/InstantID%20Zero-shot%20Identity-Preserving%20Generation%20in%20Seconds.pdf)
- *Qixun Wang, Xu Bai, Haofan Wang, Zekui Qin, Anthony Chen, Huaxia Li, Xu Tang, Yao Hu*
- `Arxiv 2024`
- [CV] [Image Edit] [Diffusion model]
```
General comments on paper quality:
fairly novel; very very interesting; easy to read but the topic is unfamiliar to me; like from Lecun; 
```

```
Personal comment (in detail):
图像合成任务（ai换脸+风格迁移+图像编辑）；高效生成的同时，保存高保真度，就如题目中的"In Seconds"一样。核心部分为2个，一是Image Adapter，主要用于生成image prompt;二是IdentityNet，主要用于丰富面部信息如pose,表情等捕捉。

小红书出品，有Demo可以玩，效果还可以，挺有意思的。
```

##### [2024-05-13] [paper4]
- MyGO: Discrete Modality Information as Fine-Grained Tokens for Multi-modal Knowledge Graph Completion [[pdf]](https://arxiv.org/pdf/2404.09468v1) [[annotated pdf]](https://github.com/binchen4110/reading_papers/blob/main/commented_pdfs/MyGO%20Discrete%20Modality%20Information%20as%20Fine-Grained%20Tokens%20for.pdf)
- *Yichi Zhang, Zhuo Chen, Lingbing Guo, Yajing Xu, Binbin Hu, Ziqi Liu, Huajun Chen, Wen Zhang*
- `MM 2024`
- [Multimodal KGC] [Contrastive Learning]
```
General comments on paper quality:
fairly novel; the proposed "fine-grained" is interesting; easy to read;
```

```
Personal comment (in detail):
捕获更细粒度的多模态信息交互；代替直接编码各个模态信息，而是采用Tokenization，编码为token, 再使用transformer融合多模态多token的细粒度的信息，学习其交互；figure 5不太明白；此外，还采用了对比学习来提升表示学习。

（感悟：对比学习和GAN之类的对抗训练都可以提升表示，即可以互换）
```

##### [2024-05-12] [paper3]
- NativE: Multi-modal Knowledge Graph Completion in the Wild [[pdf]](https://www.techrxiv.org/doi/full/10.36227/techrxiv.171259566.60211714/v1) [[annotated pdf]](https://github.com/binchen4110/reading_papers/blob/main/commented_pdfs/NativE%20Multi-modal%20Knowledge%20Graph%20Completion%20in%20the%20Wild.pdf)
- *Yichi Zhang, Zhuo Chen, Lingbing Guo, Yajing Xu, Binbin Hu, Ziqi Liu, Wen Zhang, Huajun Chen*
- `SIGIR 2024`
- [Multimodal KGC]
```
General comments on paper quality:
a little novel; the proposed "Wild" scenarios problem is interesting; easy to read;
```

```
Personal comment (in detail):
解决多模态KGC中的模态diversity和imbalanced 问题，设计了relation-guide的多模态融合机制；此外设计了GAN，对抗训练机制来提升表示学习和模型鲁棒性，并理论上证明了基于RotatE的score function满足K-Lipschitz约束，理论上证明了对抗训练机制的有用性；

时间效率的figure画法很有意思。总的来说，方法不是那么惊艳。
```

##### [2024-05-11] [paper2]
- Learnable Pillar-based Re-ranking for Image-Text Retrieval [[pdf]](https://arxiv.org/pdf/2304.12570) [[annotated pdf]](https://github.com/binchen4110/reading_papers/blob/main/commented_pdfs/Learnable%20Pillar-based%20Re-ranking%20for%20Image-Text%20Retrieval.pdf)
- *Leigang Qu, Meng Liu, Wenjie Wang, Zhedong Zheng, Liqiang Nie, Tat-Seng Chua*
- `SIGIR 2023`
- [Multimodal] [Multimodal Retrieval]
```
General comments on paper quality:
fairly novel; the proposed "Pillar" method is interesting; a little complex to read;
```

```
Personal comment (in detail):
Image2text的检索任务；在re-ranking阶段，使用Image的跨模态和本模态的邻居为基底（pillar）重定义特征表示，并使用两层变化的GCN学习表示，其中邻接矩阵的部分来源于对Image表示self-attention的相似度计算，文中称之为自学习的部分。

有点变换坐标轴，重新换基的味道。
```

##### [2024-05-10] [paper1]
- Composed Image Retrieval with Text Feedback via Multi-grained Uncertainty Regularization [[pdf]](https://arxiv.org/pdf/2211.07394v6) [[annotated pdf]](https://github.com/binchen4110/reading_papers/blob/main/commented_pdfs/Composed%20Image%20Retrieval%20with%20Text%20Feedback%20via%20Multi-grained%20Uncertainty%20Regularization.pdf)
- *Yiyang Chen, Zhedong Zheng, Wei Ji, Leigang Qu, Tat-Seng Chua*
- `ICLR 2024`
- [Multimodal] [Multimodal Retrieval] [Uncertainty]
```
General comments on paper quality:
very novel; the proposed method is interesting; easy to read;
```

```
Personal comment (in detail):
多模态image retrieval; 建模coarse-grained 匹配，对目标添加高斯噪音，以建模匹配的不确定性，1对多。

思路很简单。
```
